{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3196,"status":"ok","timestamp":1709773083421,"user":{"displayName":"mu song","userId":"16660622058482949716"},"user_tz":-480},"id":"4XTAis6FSN1h","outputId":"fc5537be-cad4-4982-df29-d09be924cf79"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"executionInfo":{"elapsed":7364,"status":"ok","timestamp":1709776307027,"user":{"displayName":"mu song","userId":"16660622058482949716"},"user_tz":-480},"id":"RJD1cBG6RJes"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","from torch.optim import Adam\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader, Dataset\n","\n","USE_CUDA = True"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1709776308346,"user":{"displayName":"mu song","userId":"16660622058482949716"},"user_tz":-480},"id":"CJS-AFPMUVp1"},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, x, y):\n","        super(CustomDataset, self).__init__()\n","        self.data = torch.from_numpy(x).float().unsqueeze(1)\n","        self.labels = torch.from_numpy(y).float()\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        return self.data[idx], self.labels[idx]\n","\n","    def get_labels(self):\n","        return self.labels\n","\n","    def get_data(self):\n","        return self.data\n","\n","\n","def get_th_dataset(x, y):\n","    \"\"\"\n","    assemble a dataset with the given data and labels\n","    :param x:\n","    :param y:\n","    :return:\n","    \"\"\"\n","    _dataset = CustomDataset(x, y)\n","    return _dataset\n","\n","\n","def get_dataloader(dataset: Dataset, batch_size):\n","    \"\"\"pytorch bilstm\n","    assemble a dataloader with the given dataset\n","    :param dataset:\n","    :param batch_size:\n","    :return:\n","    \"\"\"\n","    _dataLoader = DataLoader(dataset=dataset, batch_size=batch_size, pin_memory=True,\n","                             drop_last=True, shuffle=True)\n","    return _dataLoader\n","\n","\n","def get_th_dataset(x, y):\n","    \"\"\"\n","    assemble a dataset with the given data and labels\n","    :param x:\n","    :param y:\n","    :return:\n","    \"\"\"\n","    _dataset = CustomDataset(x, y)\n","    return _dataset\n","\n","\n","def get_dataloader(dataset: Dataset, batch_size):\n","    \"\"\"\n","    assemble a dataloader with the given dataset\n","    :param dataset:\n","    :param batch_size:\n","    :return:\n","    \"\"\"\n","    _dataLoader = DataLoader(dataset=dataset, batch_size=batch_size, pin_memory=True,\n","                             drop_last=True, shuffle=True)\n","    return _dataLoader"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1933,"status":"ok","timestamp":1709776313902,"user":{"displayName":"mu song","userId":"16660622058482949716"},"user_tz":-480},"id":"USSi-aTAUgt3"},"outputs":[],"source":["file_url = \"https://raw.githubusercontent.com/txz32102/paper/main/data/drugminer/esm2_320_dimensions_with_labels.csv\"\n","df = pd.read_csv(file_url)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":591,"status":"ok","timestamp":1709776314492,"user":{"displayName":"mu song","userId":"16660622058482949716"},"user_tz":-480},"id":"7tQn6_L3Uqe1"},"outputs":[],"source":["X = df.drop(['label', 'UniProt_id'], axis=1)\n","y = df['label'].apply(lambda x: 0 if x != 1 else x).to_numpy().astype(np.int64)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","scalar = MinMaxScaler()\n","X_train = scalar.fit_transform(X_train)\n","X_test = scalar.fit_transform(X_test)\n","train_set = get_th_dataset(X_train, y_train)\n","test_set = get_th_dataset(X_test, y_test)\n","train_loader = get_dataloader(train_set, batch_size=2)\n","test_loader = get_dataloader(test_set, batch_size=len(test_set))"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"executionInfo":{"elapsed":1,"status":"ok","timestamp":1709777004503,"user":{"displayName":"mu song","userId":"16660622058482949716"},"user_tz":-480},"id":"RZ9tjthqRJex"},"outputs":[],"source":["class ConvLayer(nn.Module):\n","    def __init__(self, in_channels=1, out_channels=20, kernel_size=3):\n","        super(ConvLayer, self).__init__()\n","        self.conv = nn.Conv1d(in_channels=in_channels,\n","                              out_channels=out_channels,\n","                              kernel_size=kernel_size,  # kernel_size is now a single number\n","                              stride=1)\n","\n","    def forward(self, x):\n","        return F.relu(self.conv(x))\n","\n","\n","class PrimaryCaps(nn.Module):\n","    def __init__(self, num_capsules=4, in_channels=20, out_channels=10, kernel_size=3):\n","        super(PrimaryCaps, self).__init__()\n","        self.num_capsules = num_capsules\n","        self.out_channels = out_channels  # Save out_channels as an instance variable\n","        # Using nn.Conv1d for 1D convolution with specified parameters\n","        self.capsules = nn.ModuleList([\n","            nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=2, padding=0)\n","            for _ in range(num_capsules)])\n","\n","    def forward(self, x):\n","        u = [capsule(x) for capsule in self.capsules]\n","        u = torch.stack(u, dim=1)\n","        # Adjust the calculation of output_size based on the actual output from convolutions\n","        # Now correctly references self.out_channels\n","        output_size = u.size(-1) * self.out_channels  # Calculate based on your output size\n","        u = u.view(x.size(0), -1, self.num_capsules)  # Correctly reshape u before squashing\n","        return self.squash(u)\n","\n","    def squash(self, input_tensor):\n","        squared_norm = (input_tensor ** 2).sum(-1, keepdim=True)\n","        output_tensor = squared_norm * input_tensor / ((1. + squared_norm) * torch.sqrt(squared_norm))\n","        return output_tensor\n","\n","class DigitCaps(nn.Module):\n","    def __init__(self, num_capsules=10, num_routes=1580, in_channels=4, out_channels=16):\n","        super(DigitCaps, self).__init__()\n","\n","        self.in_channels = in_channels\n","        self.num_routes = num_routes\n","        self.num_capsules = num_capsules\n","        self.W = nn.Parameter(torch.randn(1, num_routes, num_capsules, out_channels, in_channels))\n","\n","    def forward(self, x):\n","        batch_size = x.size(0)\n","        x = torch.stack([x] * self.num_capsules, dim=2).unsqueeze(4)\n","\n","        W = torch.cat([self.W] * batch_size, dim=0)\n","        u_hat = torch.matmul(W, x)\n","\n","        b_ij = Variable(torch.zeros(1, self.num_routes, self.num_capsules, 1))\n","        USE_CUDA = torch.cuda.is_available()\n","        if USE_CUDA:\n","            b_ij = b_ij.cuda()\n","            u_hat = u_hat.cuda()\n","\n","        num_iterations = 3\n","        for iteration in range(num_iterations):\n","            c_ij = F.softmax(b_ij, dim=2)\n","            c_ij = torch.cat([c_ij] * batch_size, dim=0).unsqueeze(4)\n","\n","            s_j = (c_ij * u_hat).sum(dim=1, keepdim=True)\n","            v_j = self.squash(s_j)\n","\n","            if iteration < num_iterations - 1:\n","                a_ij = torch.matmul(u_hat.transpose(3, 4), torch.cat([v_j] * self.num_routes, dim=1))\n","                b_ij = b_ij + a_ij.squeeze(4).mean(dim=0, keepdim=True)\n","\n","        return v_j.squeeze(1)\n","\n","    def squash(self, input_tensor):\n","        squared_norm = (input_tensor ** 2).sum(-1, keepdim=True)\n","        output_tensor = squared_norm * input_tensor / ((1. + squared_norm) * torch.sqrt(squared_norm))\n","        return output_tensor\n","\n","class Decoder(nn.Module):\n","    def __init__(self):\n","        super(Decoder, self).__init__()\n","        self.classification_layers = nn.Sequential(\n","            nn.Linear(10 * 16, 128),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(128, 16),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(16, 1),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        batch_size = x.size(0)\n","        x = x.view(batch_size, -1)\n","        probabilities = self.classification_layers(x)\n","        return probabilities\n","\n","class CapsNet(nn.Module):\n","    def __init__(self):\n","        super(CapsNet, self).__init__()\n","        self.conv_layer = ConvLayer()\n","        self.primary_capsules = PrimaryCaps()\n","        self.digit_capsules = DigitCaps()\n","        self.decoder = Decoder()\n","\n","        self.mse_loss = nn.MSELoss()\n","\n","    def forward(self, data):\n","      x = self.conv_layer(data)\n","      x = self.primary_capsules(x)\n","      x = self.digit_capsules(x)\n","      x = self.decoder(x)\n","      return x\n","\n","    def loss(self, data, x, target, reconstructions):\n","        return self.margin_loss(x, target) + self.reconstruction_loss(data, reconstructions)\n","\n","    def margin_loss(self, x, labels, size_average=True):\n","        batch_size = x.size(0)\n","\n","        v_c = torch.sqrt((x**2).sum(dim=2, keepdim=True))\n","\n","        left = F.relu(0.9 - v_c).view(batch_size, -1)\n","        right = F.relu(v_c - 0.1).view(batch_size, -1)\n","\n","        loss = labels * left + 0.5 * (1.0 - labels) * right\n","        loss = loss.sum(dim=1).mean()\n","\n","        return loss\n","\n","    def reconstruction_loss(self, data, reconstructions):\n","        loss = self.mse_loss(reconstructions.view(reconstructions.size(0), -1), data.view(reconstructions.size(0), -1))\n","        return loss * 0.0005"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"executionInfo":{"elapsed":1,"status":"ok","timestamp":1709777008039,"user":{"displayName":"mu song","userId":"16660622058482949716"},"user_tz":-480},"id":"ERFmdusRRJex"},"outputs":[],"source":["capsule_net = CapsNet()\n","if USE_CUDA:\n","    capsule_net = capsule_net.cuda()\n","optimizer = Adam(capsule_net.parameters())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1709777008643,"user":{"displayName":"mu song","userId":"16660622058482949716"},"user_tz":-480},"id":"1qaN2vuuTDHT","outputId":"6467c9bb-2eb6-4c11-c1ac-a682f6211635"},"outputs":[],"source":["data, target = next(iter(train_loader))\n","\n","print(data.shape, target.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1709777009800,"user":{"displayName":"mu song","userId":"16660622058482949716"},"user_tz":-480},"id":"rcR0wN5gmgEW","outputId":"6ef36c3b-0d16-43fe-804c-180a6584d7c3"},"outputs":[],"source":["target"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":288493,"status":"error","timestamp":1709777299085,"user":{"displayName":"mu song","userId":"16660622058482949716"},"user_tz":-480},"id":"p2L4bbfFm5y8","outputId":"a14d3a5c-1c55-4650-c00f-ec1d49adbcfd"},"outputs":[],"source":["capsule_net.train()  # Set the model to training mode\n","\n","# Define the loss function and optimizer\n","criterion = nn.BCELoss()\n","optimizer = Adam(capsule_net.parameters(), lr=0.001)  # Adjust learning rate as needed\n","\n","num_epochs = 15  # Number of epochs to train for, adjust as needed\n","\n","for epoch in range(num_epochs):\n","    running_loss = 0.0\n","    for i, (data, target) in enumerate(train_loader, 0):\n","        # Assuming USE_CUDA flag is set correctly according to your setup\n","        USE_CUDA = torch.cuda.is_available()\n","        if USE_CUDA:\n","            data, target = data.cuda(), target.cuda()\n","            capsule_net.cuda()\n","\n","        # Zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # Forward pass\n","        outputs = capsule_net(data).squeeze()  # Ensure output is of correct shape (batch_size,)\n","\n","        # Compute the loss\n","        loss = criterion(outputs, target)\n","\n","        # Backward pass and optimize\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Print statistics\n","        running_loss += loss.item()\n","        if i % 10 == 9:    # Print every 10 mini-batches, adjust as needed\n","            print('[%d, %5d] loss: %.3f' %\n","                  (epoch + 1, i + 1, running_loss / 10))\n","            running_loss = 0.0\n","\n","print('Finished Training')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"aborted","timestamp":1709777299086,"user":{"displayName":"mu song","userId":"16660622058482949716"},"user_tz":-480},"id":"FZxl7tKhnoJR"},"outputs":[],"source":["capsule_net.eval()\n","correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    for data, target in train_loader:\n","        if USE_CUDA:\n","            data, target = data.cuda(), target.cuda()\n","            capsule_net.cuda()\n","\n","        outputs = capsule_net(data).squeeze()\n","\n","        predicted = (outputs > 0.5).float()\n","\n","        total += target.size(0)\n","        correct += (predicted == target).sum().item()\n","\n","accuracy = correct / total\n","print(f'Accuracy on the train set: {accuracy:.2f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":864679,"status":"ok","timestamp":1709778626189,"user":{"displayName":"mu song","userId":"16660622058482949716"},"user_tz":-480},"id":"HLsMhpIkra1-","outputId":"558b94d2-1bdd-4254-fab8-6335283b8fa5"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","# Assuming capsule_net is your Capsule Network model\n","capsule_net.train()  # Ensure the model is in training mode\n","\n","# Define the loss function and optimizer\n","criterion = nn.BCELoss()\n","optimizer = optim.Adam(capsule_net.parameters(), lr=0.001)\n","\n","num_epochs = 10  # Adjust as needed\n","\n","for epoch in range(num_epochs):\n","    # Training phase\n","    running_loss = 0.0\n","    capsule_net.train()  # Ensure the model is in training mode\n","    for i, (data, target) in enumerate(train_loader, 0):\n","        if USE_CUDA:\n","            data, target = data.cuda(), target.cuda()\n","            capsule_net.cuda()\n","\n","        optimizer.zero_grad()\n","        outputs = capsule_net(data).squeeze()\n","        loss = criterion(outputs, target)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","\n","    # Calculate training loss\n","    print(f'Epoch {epoch+1}, Loss: {running_loss/(i+1):.4f}')\n","\n","    # Evaluation phase for both training and test sets\n","    def evaluate_accuracy(data_loader):\n","        capsule_net.eval()  # Set the model to evaluation mode\n","        correct = 0\n","        total = 0\n","        with torch.no_grad():\n","            for data, target in data_loader:\n","                if USE_CUDA:\n","                    data, target = data.cuda(), target.cuda()\n","                outputs = capsule_net(data).squeeze()\n","                predicted = (outputs > 0.5).float()\n","                total += target.size(0)\n","                correct += (predicted == target).sum().item()\n","        return correct / total\n","\n","    train_accuracy = evaluate_accuracy(train_loader)\n","    print(f'Epoch {epoch+1}, Training Accuracy: {train_accuracy:.2f}')\n","\n","print('Finished Training')\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.13"}},"nbformat":4,"nbformat_minor":0}
